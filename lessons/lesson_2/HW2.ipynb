{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка необходимых библиотек\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import pymorphy2\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "\n",
    "df_news = pd.read_csv('articles.csv')\n",
    "df_users = pd.read_csv('users_articles.csv')\n",
    "df_target = pd.read_csv('users_churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Действия с вебинара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ilya.ivolgin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stopword_ru = stopwords.words('russian')\n",
    "\n",
    "# Проверка\n",
    "\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    \n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "    \n",
    "stopword_ru += additional_stopwords\n",
    "\n",
    "# Проверка\n",
    "\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        \n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        \n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        \n",
    "        if w[0] == '-': # [2]\n",
    "            \n",
    "            w = w[1:]\n",
    "            \n",
    "        if len(w)>1: # [3]\n",
    "            \n",
    "            if w in cache: # [4]\n",
    "                \n",
    "                words_lem.append(cache[w])\n",
    "                \n",
    "            else: # [5]\n",
    "                \n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords = [i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wf/0ws1q6ks6yv_xwm2_24s254h0000gn/T/ipykernel_18900/1441476588.py:16: FutureWarning: Possible nested set at position 39\n",
      "  text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "# Очистка текста\n",
    "\n",
    "df_news['title'] = df_news['title'].apply(lambda x: clean_text(x), 1)\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "# Лемматизация текста\n",
    "\n",
    "df_news['title'] = df_news['title'].apply(lambda x: lemmatization(x), 1)\n",
    "\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем список наших текстов, разбив еще и на пробелы\n",
    "\n",
    "texts = [t for t in df_news['title'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on the corpus\n",
    "\n",
    "lda = LdaModel(common_corpus, num_topics = 25, id2word = common_dictionary)\n",
    "\n",
    "# Save model to disk\n",
    "\n",
    "temp_file = datapath(\"model.lda\")\n",
    "\n",
    "lda.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk\n",
    "\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'nnnn', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'играть', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 0.35098556),\n",
       " (5, 0.11448648),\n",
       " (6, 0.03015216),\n",
       " (12, 0.05263341),\n",
       " (13, 0.040538915),\n",
       " (17, 0.024619753),\n",
       " (21, 0.07387488),\n",
       " (22, 0.29475683)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus, made of previously unseen documents\n",
    "\n",
    "other_texts = [t for t in df_news['title'].iloc[:3]]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "\n",
    "print(other_texts[2])\n",
    "\n",
    "lda[unseen_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: фонд статья земля работник мвд ск грузия\n",
      "topic_1: женщина наука nn мужчина следствие девочка вуз\n",
      "topic_2: исследование nn пенсия связанный расследование форум американский\n",
      "topic_3: рубль банк федеральный область nn депутат департамент\n",
      "topic_4: всё большой очень район проблема рынок дом\n",
      "topic_5: японский япония южный северный корея лётчик китай\n",
      "topic_6: ii орден су армения офицер сопровождать задать\n",
      "topic_7: украина политический египет фотография граница партия писать\n",
      "topic_8: китай китайский рейтинг место теория сон лауреат\n",
      "topic_9: россия сша российский nn новый глава власть\n",
      "topic_10: смерть эксперимент взрыв пострадать чиновник причина задержать\n",
      "topic_11: военный россия газ nn население первый статья\n",
      "topic_12: мозг станция тыс закон рейс принять nn\n",
      "topic_13: ракета россия фестиваль российский флот виза риа\n",
      "topic_14: научный температура изучение nn скорость русский вода\n",
      "topic_15: новый россия армия проект доход ссср первый\n",
      "topic_16: земля ребёнок остров российский механизм иск nn\n",
      "topic_17: гражданин ребёнок убийство врач мужчина белоруссия сотрудник\n",
      "topic_18: погибнуть турция турецкий дыра произойти пилот авария\n",
      "topic_19: млн цена рост санкция составить тыс проект\n",
      "topic_20: болезнь рак километр террорист юг берег боевик\n",
      "topic_21: журнал жизнь выяснить возраст автомобиль рассказывать летний\n",
      "topic_22: продукция сотрудничать принадлежащий лёд джеймс выводить корь\n",
      "topic_23: вирус туризм предприниматель бомба озеро фильм nn\n",
      "topic_24: исследование обнаружить пациент помощь экипаж проверка млрд\n"
     ]
    }
   ],
   "source": [
    "x = lda.show_topics(num_topics = 25, num_words = 7, formatted = False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "# Below Code Prints Only Words\n",
    "\n",
    "for topic,words in topics_words:\n",
    "    \n",
    "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(text):\n",
    "    \n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    \n",
    "    for i in range(25):\n",
    "        \n",
    "        if i not in not_null_topics:\n",
    "            \n",
    "            output_vector.append(0)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            output_vector.append(not_null_topics[i])\n",
    "            \n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.23847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01199</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.096547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254693</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107974</td>\n",
       "      <td>0.03022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.024863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.314230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273331</td>\n",
       "      <td>0.049796</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.091573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105871</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.149084</td>\n",
       "      <td>0.217083</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235192</td>\n",
       "      <td>0.409069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131271</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094908</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4901</td>\n",
       "      <td>0.654593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282824</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380073</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.068518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203910</td>\n",
       "      <td>0.229796</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034469</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id   topic_0   topic_1   topic_2   topic_3   topic_4   topic_5  \\\n",
       "0       6  0.000000  0.049258  0.000000  0.491971  0.000000  0.025118   \n",
       "1    4896  0.096547  0.000000  0.000000  0.000000  0.000000  0.254693   \n",
       "2    4897  0.000000  0.000000  0.348976  0.000000  0.000000  0.107974   \n",
       "3    4898  0.000000  0.000000  0.000000  0.000000  0.273331  0.049796   \n",
       "4    4899  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5    4900  0.000000  0.235192  0.409069  0.000000  0.000000  0.131271   \n",
       "6    4901  0.654593  0.000000  0.000000  0.000000  0.000000  0.282824   \n",
       "7    4902  0.000000  0.000000  0.000000  0.000000  0.000000  0.380073   \n",
       "8    4903  0.000000  0.204798  0.000000  0.000000  0.203910  0.229796   \n",
       "9    4904  0.000000  0.565015  0.000000  0.000000  0.000000  0.034469   \n",
       "\n",
       "   topic_6  topic_7   topic_8  ...  topic_15  topic_16  topic_17  topic_18  \\\n",
       "0  0.00000      0.0  0.000000  ...  0.000000   0.23847  0.000000       0.0   \n",
       "1  0.00000      0.0  0.000000  ...  0.000000   0.00000  0.000000       0.0   \n",
       "2  0.03022      0.0  0.093045  ...  0.000000   0.00000  0.024863       0.0   \n",
       "3  0.00000      0.0  0.000000  ...  0.000000   0.00000  0.000000       0.0   \n",
       "4  0.00000      0.0  0.000000  ...  0.000000   0.00000  0.000000       0.0   \n",
       "5  0.00000      0.0  0.000000  ...  0.094908   0.00000  0.000000       0.0   \n",
       "6  0.00000      0.0  0.000000  ...  0.000000   0.00000  0.000000       0.0   \n",
       "7  0.00000      0.0  0.215007  ...  0.000000   0.00000  0.000000       0.0   \n",
       "8  0.00000      0.0  0.099742  ...  0.000000   0.00000  0.000000       0.0   \n",
       "9  0.00000      0.0  0.000000  ...  0.000000   0.00000  0.000000       0.0   \n",
       "\n",
       "   topic_19  topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0       0.0  0.000000   0.01199  0.041746  0.000000       0.0  \n",
       "1       0.0  0.000000   0.00000  0.000000  0.000000       0.0  \n",
       "2       0.0  0.000000   0.00000  0.314230  0.000000       0.0  \n",
       "3       0.0  0.000000   0.00000  0.091573  0.000000       0.0  \n",
       "4       0.0  0.105871   0.00000  0.149084  0.217083       0.0  \n",
       "5       0.0  0.000000   0.00000  0.115508  0.000000       0.0  \n",
       "6       0.0  0.000000   0.00000  0.000000  0.000000       0.0  \n",
       "7       0.0  0.000000   0.00000  0.068518  0.000000       0.0  \n",
       "8       0.0  0.000000   0.00000  0.000000  0.000000       0.0  \n",
       "9       0.0  0.000000   0.00000  0.115077  0.000000       0.0  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in df_news['title'].values])\n",
    "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "topic_matrix['doc_id'] = df_news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
    "\n",
    "# Проверка\n",
    "\n",
    "topic_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc dict\n",
    "\n",
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Модифицировать код функции ``get_user_embedding`` таким образом, чтобы считалось не среднее (как в примере ``np.mean``), а медиана.\n",
    "2. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: ``roc auc``, ``precision/recall/f_score``(для 3 последних - подобрать оптимальный порог с помощью ``precision_recall_curve``, как это делалось на уроке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем еще один аргумент\n",
    "\n",
    "def get_user_embedding(user_articles_list, method):\n",
    "    \n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = method(user_vector, 0)\n",
    "    \n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embeddings(data, method):\n",
    "    \n",
    "    user_embeddings = pd.DataFrame([i for i in data.apply(lambda x: get_user_embedding(x, method), 1)])\n",
    "    user_embeddings.columns = ['topic_{}'.format(i) for i in range(25)]\n",
    "    user_embeddings['uid'] = df_users['uid'].values\n",
    "    \n",
    "    return user_embeddings[['uid']+['topic_{}'.format(i) for i in range(25)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u107120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u102277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u102444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u103439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u104300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u102598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u107753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u103650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u106926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u103486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  churn\n",
       "0  u107120      0\n",
       "1  u102277      0\n",
       "2  u102444      0\n",
       "3  u103439      0\n",
       "4  u104300      0\n",
       "5  u102598      0\n",
       "6  u107753      0\n",
       "7  u103650      0\n",
       "8  u106926      0\n",
       "9  u103486      0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка df_target\n",
    "\n",
    "df_target.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test\n",
    "\n",
    "def get_trains_tests(df_users, df_target, method_list=[np.mean, np.median, np.max]):\n",
    "    \n",
    "    trains_tests = []\n",
    "    \n",
    "    for method in method_list:\n",
    "        \n",
    "        user_embeddings = get_user_embeddings(df_users['articles'], method)\n",
    "        X = pd.merge(user_embeddings, df_target, 'left')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X[['topic_{}'.format(i) for i in range(25)]], \n",
    "            X['churn'], random_state = 0\n",
    "        )\n",
    "\n",
    "        trains_tests += [(X_train, X_test, y_train, y_test, method.__name__,)]\n",
    "        \n",
    "    return trains_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка\n",
    "\n",
    "train_tests = get_trains_tests(df_users, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method mean: ROC_AUC=0.958865 Best Threshold=0.224340, F-Score=0.713, Precision=0.636, Recall=0.812\n",
      "Method median: ROC_AUC=0.986918 Best Threshold=0.260489, F-Score=0.849, Precision=0.829, Recall=0.869\n",
      "Method amax: ROC_AUC=0.978171 Best Threshold=0.381780, F-Score=0.817, Precision=0.878, Recall=0.763\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for train_test in train_tests:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, method_name = train_test\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    \n",
    "    # Обучение\n",
    "    \n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    preds = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "    \n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    ix = np.argmax(fscore)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_true=y_test, y_score=preds)\n",
    "\n",
    "    results += [roc_auc, precision[ix], recall[ix], fscore[ix], thresholds[ix]]\n",
    "\n",
    "    print('Method %s: ROC_AUC=%f Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (method_name,\n",
    "                                                                            roc_auc,\n",
    "                                                                            thresholds[ix], \n",
    "                                                                            fscore[ix],\n",
    "                                                                            precision[ix],\n",
    "                                                                            recall[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** если требуется увеличить ``Recall``, то ``median`` для рассчета embedding. Если ``Precison``, то ``max``."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
